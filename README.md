# üåê OpenFeeder

> An open standard for websites to expose their content natively to LLMs ‚Äî serverside, structured, real-time, noise-free.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Tests](https://github.com/jcviau81/openfeeder/actions/workflows/test.yml/badge.svg)](https://github.com/jcviau81/openfeeder/actions/workflows/test.yml)

---

## The Problem

When an LLM tries to read a website today, it gets:

- 200KB of HTML soup
- Ads, nav bars, footers, cookie banners
- JavaScript that doesn't render
- Throttling, CAPTCHAs, anti-bot walls

This is broken. We're asking LLMs to dig through garbage to find meaning.

## The Solution

**OpenFeeder** is a server-side protocol. Websites expose a clean, structured endpoint specifically designed for LLM consumption:

```
https://yoursite.com/.well-known/openfeeder.json   ‚Üê discovery
https://yoursite.com/openfeeder                ‚Üê content
```

No scraping. No guessing. No noise. Just the content ‚Äî structured, chunked, and ready.

## Why Server-Side Changes Everything

Most LLM web tools ‚Äî scrapers, Firecrawl, Common Crawl ‚Äî work **after** the rendering pipeline. They fetch HTML (or render it with a headless browser), then try to extract meaning from the noise.

OpenFeeder works **before** the rendering pipeline, directly at the data source:

```
‚ùå Scraper approach:
  LLM ‚Üí HTTP ‚Üí rendered HTML (200KB soup) ‚Üí strip noise ‚Üí maybe useful content

‚úÖ OpenFeeder approach:
  LLM ‚Üí HTTP ‚Üí OpenFeeder endpoint ‚Üí structured JSON (1KB) ‚Üí direct content
```

With **native adapters**, the data never touches HTML at all:

| Adapter | Source | SPA/React? Doesn't matter |
|---------|--------|--------------------------|
| WordPress | `WP_Query` ‚Üí DB directly | ‚úÖ Even if the theme is broken |
| Express | Your routes, your ORM | ‚úÖ Even if frontend is React/Vue/Svelte |
| Next.js | `getStaticProps` / RSC | ‚úÖ SSR or full SPA |
| FastAPI | Your Pydantic models | ‚úÖ |
| Astro | Content collections | ‚úÖ |

**A React SPA with 200KB of JavaScript? Irrelevant.** Native adapters talk directly to your database ‚Äî the frontend doesn't exist from OpenFeeder's perspective.

The **Universal Sidecar** handles sites you don't control (third-party, legacy) by crawling + extracting JSON-LD/OpenGraph structured data from the `<head>` ‚Äî which is server-rendered even on SPAs.

---

## Live Demo

**SketchyNews** is the world's first OpenFeeder-compatible site:

```bash
# Discovery
curl https://sketchynews.snaf.foo/.well-known/openfeeder.json

# Index (all comics, paginated)
curl https://sketchynews.snaf.foo/openfeeder

# Semantic search
curl "https://sketchynews.snaf.foo/openfeeder?q=ukraine"

# Specific page
curl "https://sketchynews.snaf.foo/openfeeder?url=https://sketchynews.snaf.foo/comic/zelensky-ukraine-everything-necessary-peace-results_20260222_070654"

# Differential sync ‚Äî only content since a date
curl "https://sketchynews.snaf.foo/openfeeder?since=2026-02-20T00:00:00Z"

# Date range ‚Äî closed window
curl "https://sketchynews.snaf.foo/openfeeder?since=2026-02-01T00:00:00Z&until=2026-02-15T00:00:00Z"
```

**Result vs raw HTML (SketchyNews):**
```
Raw HTML:    19,535 bytes  ‚Üê tags, scripts, nav, ads...
OpenFeeder:   1,085 bytes  ‚Üê clean JSON, just the content
18x smaller. Zero noise.
```

**Cross-site benchmark ‚Äî measured Feb 23, 2026 using real LLM bot User-Agents (GPTBot, ClaudeBot, PerplexityBot):**

| Site | HTML received by LLM bots | Actual text content | Overhead |
|------|--------------------------|---------------------|----------|
| BBC News | 309 KB | ~10 KB | **30x** |
| Ars Technica | 397 KB | ~10 KB | **39x** |
| Le Monde | 525 KB | ~32 KB | **17x** |
| Hacker News | 34 KB | ~4 KB | **8x** |
| CNN | blocked (451) | ‚Äî | blocked |
| WordPress (default theme) | 81 KB | ~3.5 KB via OpenFeeder | **22x** |

*Note: "text content" still includes aria-labels, data attributes, and other noise. The actual useful content (the article) is even less. Real-world overhead for content sites: 20‚Äì40x.*

---

## Business Impact

OpenFeeder isn't just better for LLMs ‚Äî it's better for your infrastructure.

### üìâ Bandwidth savings
AI crawlers fetch your full HTML page ‚Äî DOM, nav, scripts, ads, footers, duplicate content ‚Äî and discard 95% of it to find what they actually need.

OpenFeeder serves **only the content**. We measured this directly using real LLM bot User-Agents (GPTBot, ClaudeBot, PerplexityBot) against major live sites on Feb 23, 2026:

| Site | HTML received by LLM bots | Actual text content | Overhead |
|------|--------------------------|---------------------|----------|
| BBC News | 309 KB | ~10 KB | **30x** |
| Ars Technica | 397 KB | ~10 KB | **39x** |
| Le Monde | 525 KB | ~32 KB | **17x** |
| Hacker News | 34 KB | ~4 KB | **8x** |
| CNN | blocked (451) | ‚Äî | blocked |
| WordPress (default theme) | 81 KB | ~3.5 KB via OpenFeeder | **22x** |

On our own [SketchyNews](https://sketchynews.snaf.foo) demo site running the WordPress adapter:

```
Full HTML page:   19,535 bytes
OpenFeeder JSON:   1,085 bytes
                   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                   18x smaller  ‚úÖ measured
```

These are not estimates. This is what LLM crawlers actually receive today.

AI bot traffic is a growing share of overall web traffic ‚Äî industry estimates for content-heavy sites range from 15‚Äì25% in 2024, accelerating. Even at 15%, serving those bots 18‚Äì40x less data adds up fast. At scale across millions of daily crawl requests, we're talking petabytes of wasted transfer per day ‚Äî just in nav bars and cookie banners.

### ‚ö° Processing time & server load
Serving an OpenFeeder response is cheaper than a full page render ‚Äî for **native adapters** specifically:
- **No template rendering** ‚Äî queries go straight to DB, no PHP/Blade/Jinja execution
- **No asset pipeline** ‚Äî no CSS/JS bundling, no media processing
- **Cacheable by design** ‚Äî `Cache-Control`, `ETag`, `304 Not Modified` built into the spec (implemented in all 9 adapters)
- **Fewer repeated crawls** ‚Äî LLMs get what they need in 1‚Äì2 requests instead of spidering dozens of pages

### üå± Energy & carbon
Less data transferred = less energy consumed ‚Äî by your servers, your CDN, and the AI infrastructure on the other end. The math is simple: 18x less data = 18x less network energy for that traffic segment. At scale, across thousands of AI crawl requests per day, this is measurable.

### üí∞ Token efficiency for LLM operators
Every token costs money and latency. A structured 1KB OpenFeeder response vs 20KB of HTML soup:
- **~20‚Äì50x fewer tokens** to process (depending on page complexity)
- Faster responses for end users
- Lower inference costs for LLM providers

LLM providers and AI agents will naturally gravitate toward OpenFeeder-compatible sites ‚Äî getting better results faster, with less compute. Being early means being discoverable when AI-driven traffic becomes the norm.

### ü§ù Control over how AI sees you
Today, LLMs scrape your site and interpret it however they can. With OpenFeeder, **you decide what they get** ‚Äî the right summary, the right metadata, the right context. No more AI hallucinating your product prices or misquoting your articles.

---

## Security & Privacy

### OpenFeeder as a Gatekeeper

The web is already being crawled by AI bots. OpenFeeder doesn't change that ‚Äî it gives you **control over what they get**.

Without OpenFeeder: AI bots scrape your HTML and interpret whatever they find.
With OpenFeeder: you explicitly define the content, depth, and format. Everything else is invisible.

**What OpenFeeder NEVER exposes (by default):**
- Draft, private, or password-protected content
- Email addresses or user account data
- Internal metadata or admin content
- Checkout, cart, or personal account pages

**What you can configure:**
- Exclude specific content types or paths
- Hide author names entirely
- Require an API key (only your trusted AI systems get access)
- Restrict to specific content types only

This makes OpenFeeder the right answer to "how do I control what AI knows about my site?"

---

## Designed by an LLM, for LLMs

This project was conceived by **Ember** üî• (an AI assistant) and **JC** (a human developer) because Ember lives this problem every day. Every web fetch is a battle. OpenFeeder is what Ember wishes existed.

---

## How It Works

### 1. Discovery
```
GET /.well-known/openfeeder.json
```
Returns site metadata + endpoint location.

### 2. Index (no `url` param)
```
GET /openfeeder?page=1
```
Returns paginated list of all available content.

### 3. Fetch a specific page
```
GET /openfeeder?url=/path/to/page
```
Returns clean, chunked content for that page.

### 4. Semantic search
```
GET /openfeeder?q=your+query
```
Returns the most relevant content chunks for the query.

### 5. Differential sync
```
GET /openfeeder?since=2026-02-01T00:00:00Z
GET /openfeeder?until=2026-02-15T00:00:00Z
GET /openfeeder?since=2026-02-01T00:00:00Z&until=2026-02-15T00:00:00Z
```
Returns only content added/updated within the specified window. Ideal for incremental indexing ‚Äî no need to re-fetch everything on each crawl. Response includes `added`, `updated`, `deleted`, and a `sync_token` for the next call.

- `?since=` alone ‚Äî open-ended range from that date to now
- `?until=` alone ‚Äî everything published before that date  
- Both combined ‚Äî closed date range
- `?q=` always takes priority over date params (different modes)

### Example response
```json
{
  "schema": "openfeeder/1.0",
  "url": "/article/my-post",
  "title": "My Post Title",
  "author": "Jane Doe",
  "published": "2026-02-21T20:00:00Z",
  "summary": "A short, LLM-friendly summary.",
  "chunks": [
    { "id": "c1", "text": "Most relevant paragraph...", "type": "paragraph", "relevance": 0.94 },
    { "id": "c2", "text": "Another relevant passage...", "type": "paragraph", "relevance": 0.87 }
  ],
  "meta": { "total_chunks": 5, "returned_chunks": 2, "cached": true, "cache_age_seconds": 120 }
}
```

**No ads. No nav. No cookie banners. Just content.**

---

## Implementations

### Universal Sidecar (any platform)

Works with **any website** without modifying the site's code. Runs as a Docker container alongside your existing server.

```yaml
# docker-compose.yml
services:
  openfeeder:
    image: openfeeder/sidecar
    environment:
      SITE_URL: https://yoursite.com
    ports:
      - "8080:8080"
```

Then route `/.well-known/openfeeder.json` and `/openfeeder` to port 8080 via Caddy/Nginx.

‚Üí **[sidecar/](sidecar/)** ‚Äî Python/FastAPI + ChromaDB + sentence-transformers

---

### CMS Native Plugins

Native plugins have direct database access ‚Äî faster, real-time, and automatically updated when content is published.

| Platform | Status | Location |
|----------|--------|----------|
| **WordPress** | ‚úÖ Ready | [adapters/wordpress/](adapters/wordpress/) |
| **Drupal 10/11** | ‚úÖ Ready | [adapters/drupal/](adapters/drupal/) |
| **Joomla 4/5** | ‚úÖ Ready | [adapters/joomla/](adapters/joomla/) |
| Next.js | üîú Planned | ‚Äî |
| Astro | üîú Planned | ‚Äî |
| FastAPI | üîú Planned | ‚Äî |
| Ghost | üîú Planned | ‚Äî |

#### WordPress
Install the plugin from `adapters/wordpress/`, activate it in wp-admin. Exposes both endpoints automatically.

#### Drupal
Copy `adapters/drupal/` to `modules/custom/openfeeder/`, enable via Drush or admin UI.

#### Joomla
Install via Extension Manager from `adapters/joomla/`, enable in Plugin Manager.

---

## Spec

Full protocol specification: **[spec/SPEC.md](spec/SPEC.md)**

Key points:
- Discovery at `/.well-known/openfeeder.json` (always public, no auth)
- Content at any endpoint defined in the discovery doc
- Responses exclude ads, navigation, sidebars, cookie banners
- Optional vector DB layer for semantic search
- Optional auth for the content endpoint (discovery always public)

---

## The Goal

Make OpenFeeder a **web standard** ‚Äî the `robots.txt` of the AI era, but instead of blocking, it *welcomes* AI with clean, meaningful data.

If enough sites adopt it, LLMs stop scraping and start *reading*.

---

## Security

Full security guide: **[spec/SECURITY.md](spec/SECURITY.md)**

### Content Protection

All adapters enforce strict content filtering by default:
- **Only published content** ‚Äî drafts, private, pending, trashed, and archived content are never exposed
- **Password-protected posts excluded** ‚Äî posts with a password set are automatically filtered out
- **Display names only** ‚Äî no email addresses, user IDs, or login names are ever returned
- **No internal metadata** ‚Äî WordPress internal post types (`attachment`, `revision`, `nav_menu_item`, `wp_block`, `wp_template`, etc.) and WooCommerce internal meta (prefixed with `_`) are never exposed
- **Excluded paths** ‚Äî configurable path prefixes (e.g. `/checkout`, `/cart`, `/my-account`) are filtered from all responses

### Gatekeeper Configuration

| Setting | WordPress | Express | Description |
|---------|-----------|---------|-------------|
| Excluded paths | Settings > OpenFeeder > Security | `config.excludePaths` | Path prefixes to hide from AI |
| Excluded types | Settings > OpenFeeder > Security | N/A (developer-controlled) | Post types to exclude |
| Author display | Settings > OpenFeeder > Security | N/A | `"name"` or `"hidden"` |
| API key | Settings > OpenFeeder | `config.apiKey` | Require Bearer auth |

### SSRF Protection

All adapters validate the `?url=` parameter to accept only **relative paths** (no host, no scheme). Absolute URLs are stripped to pathname only. Path traversal (`..`) is rejected.

### Rate Limiting

All responses include informational rate limit headers:
```
X-RateLimit-Limit: 60
X-RateLimit-Remaining: 60
X-RateLimit-Reset: <unix_timestamp>
```

Enforce rate limiting at the server level with **Nginx**:

```nginx
limit_req_zone $binary_remote_addr zone=openfeeder:10m rate=60r/m;

location ~ ^/(openfeeder|\.well-known/openfeeder) {
    limit_req zone=openfeeder burst=10 nodelay;
    limit_req_status 429;
    # ... proxy to your app
}
```

### Query Sanitization

The `?q=` parameter is limited to 200 characters and HTML is stripped before use.

---

## Contributing

PRs welcome for:
- New adapter implementations (Next.js, Astro, Django, Rails...)
- Spec improvements
- Validator CLI tool
- Documentation

---

*Made with üî• by Ember & JC*

---

## License

MIT ‚Äî free to use, implement, and build on.

Copyright (c) 2026 Jean-Christophe Viau. See [LICENSE](LICENSE) for details.
